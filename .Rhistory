"Only the second test is a false-positive",
"Neither test is a false-positive"
),
first.test = c(.025,.025,.975,.975),
second.test = c(.025,.975,.025,.975)
)
bonferroni_comb$likelihood = bonferroni_comb$first.test * bonferroni_comb$second.test
knitr::kable(bonferroni_comb)
sum(bonferroni_comb$likelihood)
ggplot() +
geom_vline(xintercept = 1) +
geom_hline(yintercept = 1) +
xlim(0,1) +
ylim(0,1) +
xlab("first result p-value") +
ylab("second result p-value") +
geom_rect(
mapping = aes(
xmin = 0,
xmax = .05,
ymin = 0,
ymax = .05
),
fill = "red",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0,
xmax = .05,
ymin = .05,
ymax = 1
),
fill = "green",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0.05,
xmax = 1,
ymin = 0,
ymax = .05
),
fill = "blue",
alpha = .5
)   +
geom_rect(
mapping = aes(
xmin = .05,
xmax = 1,
ymin = 0.05,
ymax = 1
),
fill = "orange",
alpha = .5
)
bonferroni_holm_comb <- data.frame(
description = c(
"Both are false positives, but only the first test is <.025",
"Both are false positives, but only the second test is <.025",
"Both are false positives and both < .025",
"Only the first test is a false-positive",
"Only the second test is a false-positive",
"Neither test is a false-positive"
),
first.test = c(
.025, # likelihood of 0 to .025 as it is the ONLY test that it < .025
.025, # likelihood of .025 to .05 as ONLY the OTHER test is < .025
.025, # likelihood of 0 to .025 as both tests are < .025
.025, # likelihood of 0 to .025 as it is the ONLY false-positive
.95,  # likelihood of 0 to .95 as the other test is significant
.975  # likelihood of 0 to .975 as the other test is not significant
),
second.test = c(
.025, # likelihood of .025 to .05 as ONLY the OTHER test is < .025
.025, # likelihood of 0 to .025 as it is the ONLY test that it < .025
.025, # likelihood of 0 to .025 as both tests are <.025
.95,  # likelihood of 0 to .025 as it is the ONLY false-positive
.025, # likelihood of 0 to .95 as the other test is significant
.975  # likelihood of 0 to .975 as the other test is not significant
)
)
bonferroni_holm_comb$likelihood = bonferroni_holm_comb$first.test * bonferroni_holm_comb$second.test
# knitr::kable(bonferroni_holm_comb)
sum(bonferroni_holm_comb$likelihood)
ggplot() +
geom_vline(xintercept = 1) +
geom_hline(yintercept = 1) +
xlim(0,1) +
ylim(0,1) +
xlab("First result p-value") +
ylab("Second result p-value") +
geom_rect(
mapping = aes(
xmin = .0,
xmax = .025,
ymin = 0,
ymax = .025
),
fill = "blue",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0,
xmax = .025,
ymin = .025,
ymax = .05
),
fill = "red",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = .025,
xmax = .05,
ymin = 0,
ymax = .025
),
fill = "green",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0.05,
xmax = 1,
ymin = 0,
ymax = .025
),
fill = "purple",
alpha = .5
)   +
geom_rect(
mapping = aes(
xmin = 0.0,
xmax = .025,
ymin = 0.05,
ymax = 1
),
fill = "brown",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0.025,
xmax = 1,
ymin = 0.025,
ymax = 1
),
fill = "black",
alpha = .5
)
ggplot() +
geom_vline(xintercept = 1) +
geom_hline(yintercept = 1) +
xlim(0,1) +
ylim(0,1) +
xlab("First result p-value") +
ylab("Second result p-value") +
geom_rect(
mapping = aes(
xmin = .0,
xmax = .025,
ymin = 0,
ymax = .025
),
fill = "blue",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0,
xmax = .025,
ymin = .025,
ymax = .05
),
fill = "red",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = .025,
xmax = .05,
ymin = 0,
ymax = .025
),
fill = "green",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0.05,
xmax = 1,
ymin = 0,
ymax = .025
),
fill = "purple",
alpha = .5
)   +
geom_rect(
mapping = aes(
xmin = 0.0,
xmax = .025,
ymin = 0.05,
ymax = 1
),
fill = "brown",
alpha = .5
) +
geom_rect(
mapping = aes(
xmin = 0.025,
xmax = 1,
ymin = 0.025,
ymax = 1
),
fill = "black",
alpha = .5
)
install.packages(c("askpass", "credentials", "DescTools", "deSolve", "dplyr", "Matrix", "MatrixModels", "rematch", "StanHeaders", "yulab.utils"))
install.packages(c("DescTools", "deSolve", "Matrix", "MatrixModels", "StanHeaders"))
install.packages(c("DescTools", "deSolve", "Matrix", "MatrixModels", "StanHeaders"))
>>>>>>> Stashed changes
library(plotly)
detach("package:plotly", unload = TRUE)
install.packages("eulerr")
install.packages("pwr")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(openxlsx)
# clear environment
rm(list = ls())
# change wd
current_wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(current_wd)
# load csv file with payment info
excel_file <- read.xlsx("../../Prolific_payments.xlsx")
# look for all csv files in sub-folder
csv_files <- list.files(pattern = "csv", recursive = F)
i=1
as.Date(file.info(csv_files[i)$mtime)
as.Date(file.info(csv_files[i])$mtime)
file.info(csv_files[i])$mtime
file.info(csv_files[i])$ctime
file.info(csv_files[i])
file.info(paste(current_wd, csv_files[i], sep=""))
file.info(paste(current_wd, csv_files[i], sep="/"))
file.info(paste(current_wd, csv_files[i], sep="/"))$ctime
file.info(paste(current_wd, csv_files[i], sep="/"))$mtime
as.datfile.info(paste(current_wd, csv_files[i], sep="/"))$mtime
as.Date(file.info(paste(current_wd, csv_files[i], sep="/"))$mtime)
a <- as.Date(file.info(paste(current_wd, csv_files[i], sep="/"))$mtime)
a <- as.Date(file.info(paste(current_wd, csv_files, sep="/"))$mtime)
a
a <- as.Time(file.info(paste(current_wd, csv_files, sep="/"))$mtime)
a <- (file.info(paste(current_wd, csv_files, sep="/"))$mtime)
a
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(openxlsx)
# clear environment
rm(list = ls())
# change wd
current_wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(current_wd)
# load csv file with payment info
excel_file <- read.xlsx("../../Prolific_payments.xlsx")
# look for all csv files in sub-folder
csv_files <- list.files(pattern = "csv", recursive = F)
# loop over the csv files in the 'Task' subfolder
for (i in 1 :length(csv_files)){
# load the csv file
data <- read.csv(csv_files[i])
# print the filename
print(csv_files[i])
# get the Prolific_ID
prolific_id <- unique(data$subject_id)
# check if the csv has already been processed
if (!(prolific_id %in% excel_file$Prolific.ID)){
# check if the participant has reached the test phase
if ("exp_stage" %in% colnames(data)==TRUE) {
# filter just the trials relative to the test phase
df <- data %>%
filter(trial_type == "poldrack-single-stim" & exp_stage == "test")
# check if they had the screen in full mode for all the trials
full_screen_pass <- all(tolower(df$full_screen) == 'true')
# check if they got to the last trial
trial_num_pass <- max(df$trial_num, na.rm = TRUE) == 199
# check if they had any focus shift
focus_shift_pass <- all(df$focus_shifts == 0)
# if they they had the screen in full mode for all the trials, then they pass the full screen check
full_screen_status <- ifelse(full_screen_pass, 'Y', 'N')
# if they they had no focu shift, then they pass the focus shift check
focus_shift_status <- ifelse(focus_shift_pass, 'Y', 'N')
# if they they got to the last trial, then they pass the trial number check
trial_num_status <- ifelse(trial_num_pass, 'Y', 'N')
completed_task <- ifelse(trial_num_pass, 'Y', 'N')
# if they had passed all 3 checks, then we need to pay them
due_payment <- ifelse(full_screen_pass & focus_shift_pass & trial_num_pass, 'Y', 'N')
# if participant did not reach the test phase we do not need to pay them
} else {
full_screen_status <-  'N'
focus_shift_status <-  'N'
trial_num_status <-  'N'
due_payment <-  'N'
completed_task <-  'N'
}
# Create tibble
new_row <- tibble(
'Prolific.ID' = prolific_id,
'Creation Time' = file.info(paste(current_wd, csv_files[i], sep="/"))$ctime,
'Modification Time' = file.info(paste(current_wd, csv_files[i], sep="/"))$mtime,
'Completed.questionnaire' = 'Y',
'Passed.questionnaire' = 'Y',
'Attention.check' = 'Y',
'Completed.task' = completed_task,
'Full.screen.pass' = full_screen_status,
'Focus.shift.pass' = focus_shift_status,
'Trial.N.passed' = trial_num_status,
'Status' = 'Completed',
'Due.payment' = due_payment,
'Paid' = "",
'Due.bonus' = due_payment,
'Bonus.paid' = "",
'Data.archived.from.server' = "Y"
)
# check if the excel file has at least one row
if (nrow(excel_file)==0){
excel_file <-  new_row
}else{
# add the row for the participant to the excel file
excel_file <- rbind(excel_file, new_row)
}
# save the excel file
write.xlsx(excel_file, "../../Prolific_payments.xlsx", rowNames = FALSE)
}
}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(openxlsx)
# clear environment
rm(list = ls())
# change wd
current_wd <- dirname(rstudioapi::getSourceEditorContext()$path)
setwd(current_wd)
# load csv file with payment info
excel_file <- read.xlsx("../../Prolific_payments.xlsx")
# look for all csv files in sub-folder
csv_files <- list.files(pattern = "csv", recursive = F)
# loop over the csv files in the 'Task' subfolder
for (i in 1 :length(csv_files)){
# load the csv file
data <- read.csv(csv_files[i])
# print the filename
print(csv_files[i])
# get the Prolific_ID
prolific_id <- unique(data$subject_id)
# check if the csv has already been processed
if (!(prolific_id %in% excel_file$Prolific.ID)){
# check if the participant has reached the test phase
if ("exp_stage" %in% colnames(data)==TRUE) {
# filter just the trials relative to the test phase
df <- data %>%
filter(trial_type == "poldrack-single-stim" & exp_stage == "test")
# check if they had the screen in full mode for all the trials
full_screen_pass <- all(tolower(df$full_screen) == 'true')
# check if they got to the last trial
trial_num_pass <- max(df$trial_num, na.rm = TRUE) == 199
# check if they had any focus shift
focus_shift_pass <- all(df$focus_shifts == 0)
# if they they had the screen in full mode for all the trials, then they pass the full screen check
full_screen_status <- ifelse(full_screen_pass, 'Y', 'N')
# if they they had no focu shift, then they pass the focus shift check
focus_shift_status <- ifelse(focus_shift_pass, 'Y', 'N')
# if they they got to the last trial, then they pass the trial number check
trial_num_status <- ifelse(trial_num_pass, 'Y', 'N')
completed_task <- ifelse(trial_num_pass, 'Y', 'N')
# if they had passed all 3 checks, then we need to pay them
due_payment <- ifelse(full_screen_pass & focus_shift_pass & trial_num_pass, 'Y', 'N')
# if participant did not reach the test phase we do not need to pay them
} else {
full_screen_status <-  'N'
focus_shift_status <-  'N'
trial_num_status <-  'N'
due_payment <-  'N'
completed_task <-  'N'
}
# Create tibble
new_row <- tibble(
'Prolific.ID' = prolific_id,
'Creation Time' = file.info(paste(current_wd, csv_files[i], sep="/"))$ctime,
'Modification Time' = file.info(paste(current_wd, csv_files[i], sep="/"))$mtime,
'Completed.questionnaire' = 'Y',
'Passed.questionnaire' = 'Y',
'Attention.check' = 'Y',
'Completed.task' = completed_task,
'Full.screen.pass' = full_screen_status,
'Focus.shift.pass' = focus_shift_status,
'Trial.N.passed' = trial_num_status,
'Status' = 'Completed',
'Due.payment' = due_payment,
'Paid' = "",
'Due.bonus' = due_payment,
'Bonus.paid' = "",
'Data.archived.from.server' = "Y"
)
# check if the excel file has at least one row
if (nrow(excel_file)==0){
excel_file <-  new_row
}else{
# add the row for the participant to the excel file
excel_file <- rbind(excel_file, new_row)
}
# save the excel file
write.xlsx(excel_file, "../../Prolific_payments.xlsx", rowNames = FALSE)
}
}
View(excel_file)
write.xlsx(excel_file, "../../Prolific_payments.xlsx", rowNames = FALSE)
file.info(paste(current_wd, csv_files[i], sep="/"))
a <- file.info(paste(current_wd, csv_files[i], sep="/"))
View(a)
reticulate::repl_python()
df <- read.csv("df_reduced.csv")
df <- read.csv("../../../../Downloads/df_reduced.csv")
df$sex_string <- ifelse(df$sex == 1, "male", "female")
table_output <- table(df$sex_string, df$group)
chisq.test(table_output)
fisher.test(table_output)
fisher.test(table_output)
library(psych)
phi(table_output, digits = 3)
phi(table_output10, digits = 3)
table_output10 <- 10*table_output
table_output10
library(psych)
phi(table_output, digits = 3)
phi(table_output10, digits = 3)
chi_output <- chisq.test(table_output)
chi_output # to show the result
chi_10_output <- chisq.test(table_output10)
chi_10_output # to show the result
library(confintr)
phi(table_output, digits = 7)
phi(table_output10, digits = 7)
cramersv(table_output)
cramersv(table_output10)
df$small_large_group <- NA
df$small_large_group[df$random <= 5] <- "small"
df$small_large_group[df$random >= 6] <- "large"
Mean_anx <- tapply(
# the vector you will be analysing
df$anx,
# how you will group the data
INDEX = df$small_large_group,
# what function you will apply to the data
FUN = mean,
na.rm = T
)
Mean_anx
SD_anx <- tapply(df$anx, INDEX = df$small_large_group, FUN = sd, na.rm = T)
SD_anx
N_anx <- tapply(df$anx, INDEX = df$small_large_group, FUN = length)
N_anx
rbind(Mean_anx, SD_anx, N_anx)
describeBy(
# columns you want to describe
df[, c("ext", "anx")],
# column you want to group your participants by
group = df$small_large_group
)
barplot_anx <- barplot(Mean_anx, cex.axis = 1.5, cex.names = 1.5, main = "Group difference in anxiety")
barplot_anx
Mean_ext <- tapply(df$ext, INDEX = df$small_large_group, FUN = mean, na.rm = T)
SD_ext <- tapply(df$ext, INDEX = df$small_large_group, FUN = sd, na.rm = T)
N_ext <- tapply(df$ext, INDEX = df$small_large_group, FUN = length)
barplot_ext <- barplot(Mean_ext, cex.axis = 1.5, cex.names = 1.5, main = "Group difference in extraversion")
rand_sample <- rnorm(16, mean = 100, sd = 40)
mean(rand_sample)
sd(rand_sample)
large_anxiety <- df$anx[df$small_large_group == "large"]
large_anxiety_se <- sd(large_anxiety)/sqrt(length(large_anxiety))
large_anxiety_mean <- mean(large_anxiety)
large_anxiety_lower <- large_anxiety_mean - 1.96 * large_anxiety_se
large_anxiety_upper <- large_anxiety_mean + 1.96 * large_anxiety_se
large_anxiety_lower
large_anxiety_upper
cohen.d(df$anx, df$small_large_group)
large_anxiety <- df$anx[df$small_large_group == "large"]
large_anxiety_se <- sd(large_anxiety)/sqrt(length(large_anxiety))
large_anxiety_mean <- mean(large_anxiety)
large_anxiety_lower <- large_anxiety_mean - 1.96 * large_anxiety_se
large_anxiety_upper <- large_anxiety_mean + 1.96 * large_anxiety_se
large_anxiety_lower
large_anxiety_upper
library(effsize)
install.packages("effsize")
library(effsize)
cohen.d(df$anx, df$small_large_group)
What is large_anxiety_lower?
large_anxiety_lower
large_anxiety_upper
cohen.d(df$anx, df$small_large_group)
Cohen.d(df$ext, df$small_large_group)
cohen.d(df$ext, df$small_large_group)
df$ext
cohen.d(df$ext, df$small_large_group, na.rm = T)
interviews
interviews <- read.csv("../../../../Downloads/SAFI_clean.csv")
