filter(shuffle_2 == "Taboo" & condition_name == "Text Instructions") %>%
summarise(cd1 = survey_cd_e1_value,
cd2 = survey_cd_e2_value,
cd3 = survey_cd_e3_value,
cd4 = survey_cd_e4_value,
cd5 = survey_cd_e5_value,
cd6 = survey_cd_e6_value,
cd7 = survey_cd_e7_value,
cd8 = survey_cd_e8_value,
cd9 = survey_cd_e9_value,
cd10 = survey_cd_e10_value,
cd11 = survey_cd_e11_value,
cd12 = survey_cd_e12_value,
cd13 = survey_cd_e13_value,
cd14 = survey_cd_e14_value,
cd15 = survey_cd_e15_value
) %>% na.omit()
# Calculate cronbach alpha and assign to a variabe
cog_dis.text.alpha <- psych::alpha(df.cog_dis.text)
# ------------------
# Video Instructions
# ------------------
# Create a dataframe of the individual raw cognitive dissonance scores post taboo vocalisation for the video instruction sessions
df.cog_dis.video <- df.raw %>%
filter(shuffle_2 == "Taboo" & condition_name == "Video Instructions") %>%
summarise(cd1 = survey_cd_e1_value,
cd2 = survey_cd_e2_value,
cd3 = survey_cd_e3_value,
cd4 = survey_cd_e4_value,
cd5 = survey_cd_e5_value,
cd6 = survey_cd_e6_value,
cd7 = survey_cd_e7_value,
cd8 = survey_cd_e8_value,
cd9 = survey_cd_e9_value,
cd10 = survey_cd_e10_value,
cd11 = survey_cd_e11_value,
cd12 = survey_cd_e12_value,
cd13 = survey_cd_e13_value,
cd14 = survey_cd_e14_value,
cd15 = survey_cd_e15_value
) %>% na.omit()
# Calculate cronbach alpha and assign to a variable
cog_dis.video.alpha <- psych::alpha(df.cog_dis.video)
## ============ ##
## CREATE TABLE ##
## ============ ##
# Store values in a dataframe
df.alpha <- data.frame()
# Create a column of testing sessions labels
df.alpha <- cbind.data.frame(c("Supervisor", "Text", "Video"))
# Add a column with the relevant cronbach alpha scores
df.alpha$alpha <- cbind(c(cog_dis.rs.alpha$total[[1]], cog_dis.text.alpha$total[[1]], cog_dis.video.alpha$total[[1]]))
# Rename column names to make them easier to understand
names(df.alpha) <- c("Testing Session", "Cronbach’s α")
# Set up the table
alpha.table <- flextable(df.alpha) %>%
width(width = 1.25) %>%
bold(i = ~`Testing Session` > 0.9, j = 2) %>%
bold(i = ~`Testing Session` < 0.7, j = 2) %>%
colformat_double(j = 2, digits = 3) %>%
align(part = "all", j = -1, align = "center") %>%
hline_bottom(border = fp_border(color="black", width = 1)) %>%
hline_top(part="all", border = fp_border(color="black", width = 1)) %>%
border_inner_h(part="header", border = fp_border(color="black", width = 1)) %>%
fix_border_issues(part = "body")
# Output the table
alpha.table
# Chunk 4: h1_risk_aversion
## ============ ##
## DESCRIPTIVES ##
## ============ ##
# Create an empty dataframe for the BART descriptives
BART.descriptives <- data.frame
# Calculate the mean, standard deviation for the BART Pumps grouped by condition (Taboo/Non-Taboo) and session type
BART.descriptives <- df.final %>% group_by(Word, Session.Type) %>%
summarise(mean = mean(Pumps),
sd = sd(Pumps))
# Calculate the standard error for each BART score and add as a new column in the BART descriptives dataframe (this is needed purely to create the values so I can overwrite them in a minute)
BART.descriptives$se <- BART.descriptives$sd / sqrt(Final.Demo.N)
## ================= ##
## WITHIN SUBJECT SE ##
## ================= ##
# Create Wide format dataframe
df.bart2 <- df.bart_raw %>%
group_by(ID) %>%
summarise(T.BART.Pumps = mean(Pumps[Word=="Taboo"]),
NT.BART.Pumps = mean(Pumps[Word=="Non-Taboo"]),
Session.Type = Session[df.raw$phase_number=="1"]) %>% na.omit()
# Filter the dataframe to create separate dataframes for the different session types - this is needed as the standard error will be different between the sessions, if you don't do this, you end up with the same error bar on all sessions.
df.bart.rs <-  df.bart2 %>% filter(Session.Type == "Researcher Supervised")
df.bart.ti <-  df.bart2 %>% filter(Session.Type == "Text Instructions")
df.bart.vi <-  df.bart2 %>% filter(Session.Type == "Video Instructions")
# Remove Session Type Column or Ant's function breaks
df.bart.rs <-  df.bart.rs %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
df.bart.ti <-  df.bart.ti %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
df.bart.vi <-  df.bart.vi %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
# Assigned the within-subject standard error to a variable for each session type
bart.cousineau.SE.rs <- cousineau.SE(df.bart.rs)
bart.cousineau.SE.ti <- cousineau.SE(df.bart.ti)
bart.cousineau.SE.vi <- cousineau.SE(df.bart.vi)
# Add the relevant sessions' within subject standard error back into the respective descriptives dataframe we created earlier
BART.descriptives$se[BART.descriptives$Session.Type=="Researcher Supervised"] <- bart.cousineau.SE.rs
BART.descriptives$se[BART.descriptives$Session.Type=="Text Instructions"] <- bart.cousineau.SE.ti
BART.descriptives$se[BART.descriptives$Session.Type=="Video Instructions"] <- bart.cousineau.SE.vi
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# According to Dr Haffey it's ok that it's outputting the same value twice #
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# Calculate 95% Confidence Intervals and add to the BART descriptives dataframe
BART.descriptives$CI95L <- BART.descriptives$mean - BART.descriptives$se * 1.96
BART.descriptives$CI95U <- BART.descriptives$mean + BART.descriptives$se * 1.96
# Rename header names to make more readable when outputted as a table
names(BART.descriptives) <- c("Word", "Session", "Mean", "SD", "SE", "Lower", "Upper")
# Drop the SE column as this isn't needed (this is just housekeeping)
BART.descriptives <- BART.descriptives %>% dplyr::select(-SE)
# Reorder the table columns to be correctly arranged when plotted as a table, and order the rows by Word type and then Session type
BART.descriptives <- BART.descriptives %>%
dplyr::select("Session", "Word", "Mean", "SD", "Lower", "Upper") %>%
arrange(desc(Word)) %>%
arrange(Session)
## ================= ##
## ASSUMPTION CHECKS ##
## ================= ##
# (1) Outliers → Checked via a Box Q-Q Plot of BART pump scores with those +/-3SD marked. This allowed further analysis of any identified scores as to whether they were data-entry issues or just sample variance
# ~ ~ ~ #
# TABOO #
# ~ ~ ~ #
# Create a dataframe of all the scores that is just the Taboo scores
df.outliers.taboo <- data.frame
df.outliers.taboo <- df.final %>% filter(df.final$Word=="Taboo")
# Calculate any scores that are +/- 3SD from the mean and mark them as an outlier in the dataframe
pumps.outliers.t.label <- df.outliers.taboo %>%
group_by(Session.Type) %>%
mutate(outlier = abs(Pumps - median(Pumps)) > 2 * IQR(Pumps)) %>%
filter(outlier)
# Create a boxplot of the Taboo Bart pumps with the outliers marked and labelled.
pumps.outliers <- ggplot(df.outliers.taboo, aes(Session.Type, Pumps, fill=Session.Type)) +
# scale_fill_manual(name="Session Type", values = alpha(c("skyblue1", "palegreen1", "salmon1"), 0.5), guide= "none") +
stat_boxplot(geom = "errorbar", width = 0.15, linetype="solid") +
geom_boxplot(notch=F, notchwidth = 0.8, linetype = "solid", outlier.colour="#000000",
outlier.size=2, outlier.shape=1) +
geom_boxplot(notch=F, notchwidth = 0.95, outlier.shape = NA, coef = 0) +
scale_y_continuous(limits = c(0,50), expand = c(0, 0), breaks = seq(0,50,by = 8)) +
geom_text(data=pumps.outliers.t.label, aes(label=PPT.ID), hjust = -0.15, vjust = 0.1) +
theme_classic()
# ~ ~ ~ ~ ~ #
# NON-TABOO #
# ~ ~ ~ ~ ~ #
# Create a dataframe of all the scores that is just the Non-Taboo scores
df.outliers.nt <- data.frame
df.outliers.nt <- df.final %>% filter(df.final$Word=="Non-Taboo")
# Calculate any scores that are +/- 3SD from the mean and mark them as an outlier in the dataframe
pumps.outliers.nt.label <- df.outliers.nt %>%
group_by(Session.Type) %>%
mutate(outlier = abs(Pumps - median(Pumps)) > 2 * IQR(Pumps)) %>%
filter(outlier)
# Create a boxplot of the Taboo Bart pumps with the outliers marked and labelled.
pumps.outliers.nt <- ggplot(df.outliers.nt, aes(Session.Type, Pumps, fill=Session.Type)) +
# scale_fill_manual(name="Session Type", values = alpha(c("skyblue1", "palegreen1", "salmon1"), 0.5), guide= "none") +
stat_boxplot(geom = "errorbar", width = 0.15, linetype="solid") +
geom_boxplot(notch=F, notchwidth = 0.8, linetype = "solid", outlier.colour="#000000",
outlier.size=2, outlier.shape=1) +
geom_boxplot(notch=F, notchwidth = 0.95, outlier.shape = NA, coef = 0) +
scale_y_continuous(limits = c(0,40), expand = c(0, 0), breaks = seq(0,40,by = 8)) +
geom_text(data=pumps.outliers.nt.label, aes(label=PPT.ID), hjust = -0.15, vjust = 0.1) +
theme_classic()
# ==================== #
# NORMALITY & VARIANCE #
# ==================== #
# Create an anova model per session type to assess normality and variance assumptions
anova.model.pumps <- df.final %>% group_by(Word) %>% do(model = lm(Pumps ~ Session.Type, data = .))
# (2) Homogeneity of Variance (Levene's Test → wants to be non-sig)
leveneTest(anova.model.pumps[[2]][[1]]) # Non-Taboo
leveneTest(anova.model.pumps[[2]][[2]]) # Taboo
# (3) Normal Distribution (Shaprio Wilk → wants to be non-sig)
# Get the residuals of the anova model
NT.Pumps.residuals <- residuals(object = anova.model.pumps[[2]][[1]]) # Non-Taboo
T.Pumps.residuals <- residuals(object = anova.model.pumps[[2]][[2]])  # Taboo
# Calculate Shapiro Wilk scores for each residual
shapiro.test(x = NT.Pumps.residuals) # Non-Taboo
shapiro.test(x = T.Pumps.residuals) # Taboo
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# CLT applies and Donaldson (1968) says ANOVA is robust to non-normal  #
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# (4) Mauchley's test of Sphericity → not needed as there are only 2 levels to the IVs
# (5) Independence
# Note: this is naturally assumed based on the fact testing sessions were 24 hours apart, and each balloon was new, with performance distinct/not influenced by prior balloons/testing sessions.
# (6) Interval Data
# Met as BART Pumps were measured via an integer and thus, continuous data
## ======================== ##
## 2x2 ANALYSIS OF VARIANCE ##
## ======================== ##
# Word By Order Effect ANOVA
BART.Anova2 <- df.final %>% group_by(Session.Type) %>% do(model = aov(Pumps ~ Word * Order + Error(PPT.ID/(Word)), data = .))
# Supervised
bart.rs.out <- summary(BART.Anova2[[2]][[1]])
bart.rs.out
# Text
bart.ti.out <- summary(BART.Anova2[[2]][[2]])
bart.ti.out
# Video
bart.vi.out <-summary(BART.Anova2[[2]][[3]])
bart.vi.out
# ----------------------------------------------------------------------------------------------
# Calculate Effect Size (based on Lakens [https://bit.ly/3vxfktI] -> eta2 = F * dfn/[F*dfn+dfd])
# ----------------------------------------------------------------------------------------------
# Store F statistics
bart.rs.out.f <- bart.rs.out$`Error: PPT.ID:Word`[[1]][[4]][[1]]
bart.ti.out.f <- bart.ti.out$`Error: PPT.ID:Word`[[1]][[4]][[1]]
bart.vi.out.f <- bart.vi.out$`Error: PPT.ID:Word`[[1]][[4]][[1]]
bart.order.rs.f <- bart.rs.out$`Error: PPT.ID:Word`[[1]][[4]][[2]]
bart.order.ti.f <- bart.ti.out$`Error: PPT.ID:Word`[[1]][[4]][[2]]
bart.order.vi.f <- bart.vi.out$`Error: PPT.ID:Word`[[1]][[4]][[2]]
# Store Degrees of freedom
bart.rs.out.dfn <- bart.rs.out$`Error: PPT.ID:Word`[[1]][[1]][[1]]
bart.ti.out.dfn <- bart.ti.out$`Error: PPT.ID:Word`[[1]][[1]][[1]]
bart.vi.out.dfn <- bart.vi.out$`Error: PPT.ID:Word`[[1]][[1]][[1]]
bart.order.rs.dfn <- bart.rs.out$`Error: PPT.ID:Word`[[1]][[1]][[2]]
bart.order.ti.dfn <- bart.ti.out$`Error: PPT.ID:Word`[[1]][[1]][[2]]
bart.order.vi.dfn <- bart.vi.out$`Error: PPT.ID:Word`[[1]][[1]][[2]]
bart.rs.out.dfd <- bart.rs.out$`Error: PPT.ID:Word`[[1]][[1]][[3]]
bart.ti.out.dfd <- bart.ti.out$`Error: PPT.ID:Word`[[1]][[1]][[3]]
bart.vi.out.dfd <- bart.vi.out$`Error: PPT.ID:Word`[[1]][[1]][[3]]
# ~ ~ ~ ~ ~ ~ ~
# Effect Sizes
# ~ ~ ~ ~ ~ ~ ~
# ~ ~ ~
# Order
# ~ ~ ~
# Supervised
bart.order.rs.eta <- bart.order.rs.f * bart.order.rs.dfn/(bart.order.rs.f * bart.order.rs.dfn + bart.rs.out.dfd)
bart.order.rs.eta
# Text
bart.order.ti.eta <- bart.order.ti.f * bart.order.ti.dfn/(bart.order.ti.f * bart.order.ti.dfn + bart.rs.out.dfd)
bart.order.ti.eta
# Video
bart.order.vi.eta <- bart.order.vi.f * bart.order.vi.dfn/(bart.order.vi.f * bart.order.vi.dfn + bart.rs.out.dfd)
bart.order.vi.eta
# ~ ~ ~
# Word
# ~ ~ ~
# Supervised
bart.rs.eta <- bart.rs.out.f * bart.rs.out.dfn/(bart.rs.out.f * bart.rs.out.dfn + bart.rs.out.dfd)
bart.rs.eta
# Text
bart.ti.eta<- bart.ti.out.f * bart.ti.out.dfn/(bart.ti.out.f * bart.ti.out.dfn + bart.ti.out.dfd)
bart.ti.eta
# Video
bart.vi.eta <- bart.vi.out.f * bart.vi.out.dfn/(bart.vi.out.f * bart.vi.out.dfn + bart.vi.out.dfd)
bart.vi.eta
# Chunk 5: t_bart_boxplot
# Output the taboo outliers boxplot in APA format
print(pumps.outliers +
labs(y = "Number of Pumps on unexploded balloons\n",
x = "\nSession Type",
title = "Interquartile range of unexploded BART pumps after vocalising\nF**k across each session type with outliers plotted & labeled") +
theme(plot.caption = element_text(hjust = 0),
plot.title = element_text(hjust = 0.5, vjust=5, face="bold"),
plot.margin = margin(t = 25, r = 25, b = 25, l = 25, unit = "pt"),
plot.background = element_rect(colour = "gray85", fill=NA, size=1)))
# Chunk 6: nt_bart_boxplot
# Output the non-taboo outliers boxplot in APA format
print(pumps.outliers.nt +
labs(y = "Number of Pumps on unexploded balloons\n",
x = "\nSession Type",
title = "Interquartile range of unexploded BART pumps after vocalising\nFlat across each session type with outliers plotted & labeled") +
theme(plot.caption = element_text(hjust = 0),
plot.title = element_text(hjust = 0.5, vjust=5, face="bold"),
plot.margin = margin(t = 25, r = 25, b = 25, l = 25, unit = "pt"),
plot.background = element_rect(colour = "gray85", fill=NA, size=1)))
# Remove the one outlier who looks to be a data error
# This may look at a bit odd at this point in the code as you may think "how do you know..." but it's in a separate dataframe, I just have to put it up here so it's cleaned out before I calculate the within subject error bars otherwise they're wrong
df.final.offense_clean <- df.final %>% filter(!ID %in% c("3wd83w2qeld", "q4jr98hb1u", "6dvwwdghpa7"))
## ============ ##
## DESCRIPTIVES ##
## ============ ##
# Create an empty dataframe for the Offensiveness rating VAS score descriptives
offense.descriptives <- data.frame
# Calculate the mean and standard deviation of the offensiveness rating for each word type, based on the type of session being undertaken
offense.descriptives <- df.final.offense_clean %>% group_by(Word, Session.Type) %>%
summarise(mean = mean(Offense),
sd = sd(Offense))
# This is a between subjects SE but it's needed to be replaced in a minute!
offense.descriptives$se <- offense.descriptives$sd / sqrt(Final.Demo.N)
## ================= ##
## WITHIN SUBJECT SE ##
## ================= ##
# Create Wide format dataframe
df.offense2 <- df.final.offense_clean %>%
group_by(ID) %>%
summarise(T.Offense = Offense[Word=="Taboo"],
NT.offense = Offense[Word=="Non-Taboo"],
Session.Type = Session.Type[df.raw$phase_number=="1"]) %>% na.omit()
# Filter the dataframe to create separate dataframes for each of the individual testing sessions. If you don't do this, you just get one SE values and thus, the same error bar appears on all sessions when plotted.
df.offense.rs <-  df.offense2 %>% filter(Session.Type == "Researcher Supervised")
df.offense.ti <-  df.offense2 %>% filter(Session.Type == "Text Instructions")
df.offense.vi <-  df.offense2 %>% filter(Session.Type == "Video Instructions")
# Remove Session Type Column or Ant's function breaks
df.offense.rs <- df.offense.rs %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
df.offense.ti <- df.offense.ti %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
df.offense.vi <- df.offense.vi %>% ungroup(ID) %>% dplyr::select(-c("Session.Type", "ID"))
# Assign the within-subject standard error to individual variables for the different session types
offense.cousineau.SE.rs <- cousineau.SE(df.offense.rs)
offense.cousineau.SE.ti <- cousineau.SE(df.offense.ti)
offense.cousineau.SE.vi <- cousineau.SE(df.offense.vi)
# Assign the respective within-subject standard error for each session to the relevant SS of the descriptives dataframe we created at the start
offense.descriptives$se[offense.descriptives$Session.Type=="Researcher Supervised"] <- offense.cousineau.SE.rs
offense.descriptives$se[offense.descriptives$Session.Type=="Text Instructions"] <- offense.cousineau.SE.ti
offense.descriptives$se[offense.descriptives$Session.Type=="Video Instructions"] <- offense.cousineau.SE.vi
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
# According to AH it's ok that it's outputting the same value twice #
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ #
## ============ ##
## CREATE TABLE ##
## ============ ##
# Calculate 95% Confidence Intervals and add to the existing "offense" dataframe
offense.descriptives$CI95L <- offense.descriptives$mean - offense.descriptives$se * 1.96
offense.descriptives$CI95U <- offense.descriptives$mean + offense.descriptives$se * 1.96
# Drop the SE column
offense.descriptives2 <- offense.descriptives
offense.descriptives <-  offense.descriptives %>% dplyr::select(-c("se"))
# Rename header names to make easier to read in the final table
names(offense.descriptives) <- c("Word", "Session", "Mean", "SD", "Lower", "Upper")
# Reorder the columns so they are in the correct order and then sort so Word Condition and Session Type display in the correct order too
offense.descriptives <- offense.descriptives %>%
dplyr::select("Session", "Word", "Mean", "SD", "Lower", "Upper") %>%
arrange(desc(Word)) %>%
arrange(Session)
# Plot the results as a table using flextable
offense.table <- flextable(offense.descriptives) %>%
add_header_row(values = c("Session","Word","Mean", "SD", "95% Confidence Invervals"), colwidths = c(1,1,1,1,2)) %>%
width(width = 1.25) %>%
merge_v(j = 1:4, part= "header") %>%
merge_v(j = 1:2, part= "body") %>%
valign(j = 1:4, valign = "top", part="header") %>%
valign(j = 1:2, valign = "top") %>%
colformat_double(j = 3:6, digits = 2) %>%
align(part = "all", j = -1, align = "center") %>%
align(part = "all", j = 1, align = "left") %>%
hline_bottom(border = fp_border(color="black", width = 1)) %>%
hline_top(part="all", border = fp_border(color="black", width = 1)) %>%
border_inner_h(part="header", border = fp_border(color="black", width = 1)) %>%
add_header_lines(values = "Mean VAS Offensiveness Rating") %>%
hline_top(border = fp_border(color="white", width = 1), part = "header") %>%
fix_border_issues(part = "body")
## ================= ##
## ASSUMPTION CHECKS ##
## ================= ##
# (1) Outliers → Checked via a Box Q-Q Plot of BART pump scores with those +/-3SD marked. This allowed further analysis of any identified scores as to whether they were data-entry issues or just sample variance
# ~ ~ ~ #
# TABOO #
# ~ ~ ~ #
# Create a dataframe of outliers based on their offensiveness scores for the taboo condition only - this reuses the taboo outliers dataframe created in the bart assumptions
offense.outliers.t.label <- df.outliers.taboo %>%
group_by(Session.Type) %>%
mutate(outlier = abs(Offense - median(Offense)) > 2 * IQR(Offense)) %>%
filter(outlier)
# Plot and label the outliers on a boxplot for the taboo offensiveness scores
# Note: The colour scheme for the sessions matches the same colour scheme used in the counterbalancing spreadsheet used during data collection
offense.outliers <- ggplot(df.outliers.taboo, aes(Session.Type, Offense, fill=Session.Type)) +
#scale_fill_manual(name="Session Type", values = alpha(c("skyblue1", "palegreen1", "salmon1"),0.5), guide= "none") +
stat_boxplot(geom = "errorbar", width = 0.15, linetype="solid") +
geom_boxplot(notch=F, notchwidth = 0.8, linetype = "solid", outlier.colour="#000000",
outlier.size=2, outlier.shape=1) +
geom_boxplot(notch=F, notchwidth = 0.95, outlier.shape = NA, coef = 0) +
scale_y_continuous(limits = c(1,9), expand = c(0, 0), breaks = seq(1,9,by = 1)) +
geom_text(data=offense.outliers.t.label, aes(label=PPT.ID), hjust = -0.15, vjust = 0.1) +
theme_classic()
# ~ ~ ~ ~ ~ #
# NON-TABOO #
# ~ ~ ~ ~ ~ #
# Create a dataframe of outliers based on their offensiveness scores for the non-taboo condition only - this reuses the non-taboo outliers dataframe created in the bart assumptions
offense.outliers.nt.label <- df.outliers.nt %>%
group_by(Session.Type) %>%
mutate(outlier = abs(Offense - median(Offense)) > 2 * IQR(Offense)) %>%
filter(outlier)
# Plot and label the outliers on a boxplot for the taboo offensiveness scores
# Note: The colour scheme for the sessions matches the same colour scheme used in the counterbalancing spreadsheet used during data collection
offense.outliers.nt <- ggplot(df.outliers.nt, aes(Session.Type, Offense, fill=Session.Type)) +
#scale_fill_manual(name="Session Type", values = alpha(c("skyblue1", "palegreen1", "salmon1"),0.5), guide= "none") +
stat_boxplot(geom = "errorbar", width = 0.15, linetype="solid") +
geom_boxplot(notch=F, notchwidth = 0.8, linetype = "solid", outlier.colour="#000000",
outlier.size=2, outlier.shape=1) +
geom_boxplot(notch=F, notchwidth = 0.95, outlier.shape = NA, coef = 0) +
scale_y_continuous(limits = c(1,6), expand = c(0, 0), breaks = seq(1,6, by = 1)) +
geom_text(data=offense.outliers.nt.label, aes(label=PPT.ID), hjust = -0.15, vjust = 0.1) +
theme_classic()
# ==================== #
# NORMALITY & VARIANCE #
# ==================== #
# Create an anova model per session type to assess normality and variance assumptions
anova.model.offense <- df.final.offense_clean %>% group_by(Word) %>% do(model = lm(Offense ~ Session.Type, data = .))
# (2) Homogeneity of Variance (Leven's Test → wants to be non-sig)
leveneTest(anova.model.offense[[2]][[1]]) # Non-Taboo
leveneTest(anova.model.offense[[2]][[2]]) # Taboo
# (3) Normal Distribution (Shaprio Wilk → wants to be non-sig)
# Get residuals from ANOVA model
NT.Offense.residuals <- residuals(object = anova.model.offense[[2]][[1]]) # Non-Taboo
T.Offense.residuals <- residuals(object = anova.model.offense[[2]][[2]])  # Taboo
# Check normality via Shapiro Wilk tests for the residuals of each word type
shapiro.test(x = NT.Offense.residuals) # Non-Taboo
shapiro.test(x = T.Offense.residuals) # Taboo
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# CLT applies and Donaldson (1968) says ANOVA is robust to non-normal  #
# ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~  #
# (4) Mauchley's test of Sphericity needed as there are three levels to session type → needs to be greater than 0.05
mauch.anova.offense <- anova_test(data = df.final.offense_clean, dv = Offense, wid = PPT.ID, within = c(Word, Session.Type), between = Order)
mauch.anova.offense$`Mauchly's Test for Sphericity`
# (5) Independence
# Note: this is naturally assumed based on the fact testing sessions were a minimum of 24 hours apart, and each VAS scale was reset to a mid point before participants made a rating, and the exact value of each rating previously made was not displayed to participants.
# (6) Interval Data
# Met as Offensiveness was measured via an integer and thus, interval data
## ====================== ##
## 2x2 ORDER EFFECT ANOVA ##
## ====================== ##
# I think R would do this automaticall,y but just to be safe, I'm changing the PPT ID to be a factor.
df.final.offense_clean$PPT.ID <- as.factor(df.final.offense_clean$PPT.ID)
# Run ANOVA - this is a repeated measures anova hence the need for Error()
Offense.Anova <- df.final.offense_clean %>% group_by(Session.Type) %>% do(model = aov(Offense ~ Word * Order + Error(PPT.ID/(Word)), data = .))
# -------------
# Output ANOVAs
# -------------
# Supervised
offense.anova.order.rs <- summary(Offense.Anova[[2]][[1]])
offense.anova.order.rs
# Text
offense.anova.order.ti <- summary(Offense.Anova[[2]][[2]])
offense.anova.order.ti
# Video
offense.anova.order.vi <- summary(Offense.Anova[[2]][[3]])
offense.anova.order.vi
# ----------------------------------------------------------------------------------------------
# Calculate Effect Size (based on Lakens [https://bit.ly/3vxfktI] -> eta2 = F * dfn/[F*dfn+dfd])
# ----------------------------------------------------------------------------------------------
# Store F statistics
# Order
offense.order.rs.f <- offense.anova.order.rs$`Error: PPT.ID:Word`[[1]][[4]][[2]]
offense.order.ti.f <- offense.anova.order.ti$`Error: PPT.ID:Word`[[1]][[4]][[2]]
offense.order.vi.f <- offense.anova.order.vi$`Error: PPT.ID:Word`[[1]][[4]][[2]]
# Word
offense.word.rs.f <- offense.anova.order.rs$`Error: PPT.ID:Word`[[1]][[4]][[1]]
offense.word.ti.f <- offense.anova.order.ti$`Error: PPT.ID:Word`[[1]][[4]][[1]]
offense.word.vi.f <- offense.anova.order.vi$`Error: PPT.ID:Word`[[1]][[4]][[1]]
# Store Degrees of freedom
# Order
offense.order.rs.dfn <- offense.anova.order.rs$`Error: PPT.ID:Word`[[1]][[1]][[2]]
offense.order.ti.dfn <- offense.anova.order.ti$`Error: PPT.ID:Word`[[1]][[1]][[2]]
offense.order.vi.dfn <- offense.anova.order.vi$`Error: PPT.ID:Word`[[1]][[1]][[2]]
# Word
offense.word.rs.dfn <- offense.anova.order.rs$`Error: PPT.ID:Word`[[1]][[1]][[1]]
offense.word.ti.dfn <- offense.anova.order.ti$`Error: PPT.ID:Word`[[1]][[1]][[1]]
offense.word.vi.dfn <- offense.anova.order.vi$`Error: PPT.ID:Word`[[1]][[1]][[1]]
# Residuals
offense.anova.rs.dfd <- offense.anova.order.rs$`Error: PPT.ID:Word`[[1]][[1]][[3]]
offense.anova.ti.dfd <- offense.anova.order.ti$`Error: PPT.ID:Word`[[1]][[1]][[3]]
offense.anova.vi.dfd <- offense.anova.order.vi$`Error: PPT.ID:Word`[[1]][[1]][[3]]
# ~ ~ ~
# Order
# ~ ~ ~
# Supervised
offense.order.rs.eta <- offense.order.rs.f * offense.order.rs.dfn/(offense.order.rs.f * offense.order.rs.dfn + offense.anova.rs.dfd)
offense.order.rs.eta
# Text
offense.order.ti.eta <- offense.order.ti.f * offense.order.ti.dfn/(offense.order.ti.f * offense.order.ti.dfn + offense.anova.ti.dfd)
offense.order.ti.eta
# Video
offense.order.vi.eta <- offense.order.vi.f * offense.order.vi.dfn/(offense.order.vi.f * offense.order.vi.dfn + offense.anova.vi.dfd)
offense.order.vi.eta
# ~ ~ ~
# Word
# ~ ~ ~
# Supervised
offense.word.rs.eta <- offense.word.rs.f * offense.word.rs.dfn/(offense.word.rs.f * offense.word.rs.dfn + offense.anova.rs.dfd)
offense.word.rs.eta
# Text
offense.word.ti.eta <- offense.word.ti.f * offense.word.ti.dfn/(offense.word.ti.f * offense.word.ti.dfn + offense.anova.ti.dfd)
offense.word.ti.eta
# Video
offense.word.vi.eta <- offense.word.vi.f * offense.word.vi.dfn/(offense.word.vi.f * offense.word.vi.dfn + offense.anova.vi.dfd)
offense.word.vi.eta
## ========================== ##
## 1x3 BETWEEN SESSION ANCOVA ##
## ========================== ##
# Create data frame
df.ancova <- data.frame()
# Insert data from the cleaned dataframe we set up ealier
df.ancova <- cbind.data.frame(df.final.offense_clean$PPT.ID[df.final.offense_clean$Word=="Taboo"],
df.final.offense_clean$Offense[df.final.offense_clean$Word=="Taboo"],
df.final.offense_clean$Order[df.final.offense_clean$Word=="Taboo"],
df.final.offense_clean$Session.Type[df.final.offense_clean$Word=="Taboo"],
df.final.offense_clean$Offense[df.final.offense_clean$Word=="Non-Taboo"])
# Rename header names
names(df.ancova) <- c("PPT.ID", "Offense", "Order", "Session.Type", "Flat")
# Create the ANCOA, this is repeated measures in which we say that we want to factor in ppt's score for Flat, and their vocalisation order, with the Error fixed for PPT.ID within which we're manipulating the Session ID (i.e., for each PPT.ID there are difference sessiosn.type)
Offense.Ancova <- summary(aov(Offense ~ Session.Type + Order + Flat + Error(PPT.ID/(Session.Type)), data = df.ancova))
# Output the ANCOVA
Offense.Ancova
# Store F statistic
offense.session.out.f <- Offense.Ancova$`Error: PPT.ID:Session.Type`[[1]][[4]][[1]]
# Store Degrees of freedom
offense.session.out.dfn <- Offense.Ancova$`Error: PPT.ID:Session.Type`[[1]][[1]][[1]]
offense.session.out.dfd <- Offense.Ancova$`Error: PPT.ID:Session.Type`[[1]][[1]][[4]]
# Calculate Effect Size (based on Lakens [https://bit.ly/3vxfktI] -> eta2 = F * dfn/[F*dfn+dfd])
offense.session.eta <- offense.session.out.f * offense.session.out.dfn/(offense.session.out.f * offense.session.out.dfn + offense.session.out.dfd)
offense.session.eta
## -------------- ##
## POST HOC TESTS ##
## -------------- ##
# No need as no significant Word * Session interaction :-(
Offense.Anova
Offense.Anova$Session.Type
Offense.Anova$model
offense.anova.order.rs
